{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Thesis_Measure.ipynb","provenance":[{"file_id":"1PglDdkk0clR6iGyyYoNAeKUBNRuJki-d","timestamp":1594527736372}],"collapsed_sections":["ywsSpNOxNDUz","CSyXPDO9ftkE"],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ywsSpNOxNDUz"},"source":["# Setup Enviroment"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vO3IFLoLAqLl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1598323028328,"user_tz":-420,"elapsed":29000,"user":{"displayName":"TUẤN NGUYỄN","photoUrl":"","userId":"09951512662861922656"}},"outputId":"b42c9647-6e93-4579-fb32-5715976e9232"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9Sm1veihA0Al","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1598323029631,"user_tz":-420,"elapsed":30279,"user":{"displayName":"TUẤN NGUYỄN","photoUrl":"","userId":"09951512662861922656"}},"outputId":"65f2a6c7-788e-4c00-b6b5-029aca057cc8"},"source":["cd /content/drive/My Drive/Thesis/Final/GPAR/SOURCE"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/18_zdtnvoSmQEMVajU7EcjpS9fg_Cr2bC/Thesis/Final/GPAR/SOURCE\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-dMa69slB14l","colab_type":"code","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1598323035461,"user_tz":-420,"elapsed":36089,"user":{"displayName":"TUẤN NGUYỄN","photoUrl":"","userId":"09951512662861922656"}},"outputId":"d1113947-a2ce-4ab4-bb5f-b8aad5eee075"},"source":["! pip install import-ipynb"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting import-ipynb\n","  Downloading https://files.pythonhosted.org/packages/63/35/495e0021bfdcc924c7cdec4e9fbb87c88dd03b9b9b22419444dc370c8a45/import-ipynb-0.1.3.tar.gz\n","Building wheels for collected packages: import-ipynb\n","  Building wheel for import-ipynb (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for import-ipynb: filename=import_ipynb-0.1.3-cp36-none-any.whl size=2976 sha256=6c1f8cceb2a0dd8fb2b72e9a64c9924847343d8796b16125c3a0eb573c9e570a\n","  Stored in directory: /root/.cache/pip/wheels/b4/7b/e9/a3a6e496115dffdb4e3085d0ae39ffe8a814eacc44bbf494b5\n","Successfully built import-ipynb\n","Installing collected packages: import-ipynb\n","Successfully installed import-ipynb-0.1.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3FvgG55MA4v2","colab":{}},"source":["import import_ipynb as ipy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6a6n5Wp6B0du","colab_type":"code","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1598323043338,"user_tz":-420,"elapsed":43937,"user":{"displayName":"TUẤN NGUYỄN","photoUrl":"","userId":"09951512662861922656"}},"outputId":"746d91d3-8f8b-42d2-c20a-e0d5d3db8b67"},"source":["import Thesis_Undirected_GPARs_Final as undirected\n","import Thesis_Directed_GPARs_Final as directed"],"execution_count":null,"outputs":[{"output_type":"stream","text":["importing Jupyter notebook from Thesis_Undirected_GPARs_Final.ipynb\n","importing Jupyter notebook from Thesis_Directed_GPARs_Final.ipynb\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vQ1So8CH6WIt","colab":{}},"source":["import time\n","import re\n","import math\n","import queue\n","import random\n","import json\n","import multiprocessing\n","import os\n","import networkx\n","from collections import defaultdict\n","import copy\n","import progressbar"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CSyXPDO9ftkE"},"source":["# Split K Fold"]},{"cell_type":"code","metadata":{"id":"RY5QvSCcYMs3","colab_type":"code","colab":{}},"source":["# convert from drawDataFormat to GramiFormat\n","def convert_Grami(src_nodes, src_edges, start_idx, split_char):\n","    des_path = src_nodes.split('.')[0] + '.lg'\n","    with open(src_nodes, 'r') as node_f:\n","        with open(src_edges, 'r') as edge_f:\n","            with open(des_path, 'w') as des_f:\n","                des_f.write('t\\t#\\t1\\n')\n","                \n","                nodes_set = set()\n","                edges_set = set()\n","                nodes = node_f.readlines()\n","                for node in nodes:\n","                    data = node.strip('\\n').split(split_char)\n","                    nodes_set.add((int(data[0])-start_idx, data[1]))\n","                edges = edge_f.readlines()\n","                for edge in edges:\n","                    data = edge.strip('\\n').split(split_char)\n","                    if data[0] != data[1]:\n","                        edges_set.add((int(data[0])-start_idx, int(data[1])-start_idx))\n","                \n","                nodes_set = sorted(nodes_set)\n","                print('Lennodes: ', len(nodes_set))\n","                edges_set = sorted(edges_set)\n","                print('Lenedges: ', len(edges_set))\n","                for node in nodes_set:\n","                    v, l = node\n","                    des_f.write('v {} {}\\n'.format(v, l))\n","                for edge in edges_set:\n","                    v1, v2 = edge\n","                    des_f.write('e {} {} -1\\n'.format(v1, v2))\n","\n","# convert_Grami('DATASETS/CL_10M_1d8_L5/CL_10M_1d8_L5.node_labels', 'DATASETS/CL_10M_1d8_L5/CL_10M_1d8_L5.edges', 1, '\\t')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"uqeCm3AtfskD","colab":{}},"source":["def device_data(profiles_filename, relationships_filename, num_partition):\n","  def device_edges():\n","    print('Split test data......................')\n","    map_idx = {} #{file_index: set(vertex_idxs)}\n","    edges_old = [] #edges[file_index] = [[v0,v1], ....]\n","    for i in range(0, num_partition):\n","      map_idx[i] = set()\n","      edges_old.append([])\n","\n","    # des_filename = relationships_filename.split('.')[0]\n","    with open(relationships_filename, 'r') as edges_f:\n","      print('Data reading ........')\n","      lines = edges_f.readlines()\n","      print('Cal max item_per_partition ......')\n","      max_num_items_per_partition = math.ceil(len(lines)/num_partition)\n","        \n","      lines = set(lines)\n","\n","      for i in range(0, num_partition-1):\n","        print('Partition ', i, '.........')\n","        edges = random.sample(lines, max_num_items_per_partition)\n","\n","        # des_f = open(des_filename+'_'+str(i)+'.txt', 'w')\n","        for edge in edges:\n","          lines.remove(edge)\n","          data = edge.strip('\\n').split('\\t')\n","          # des_f.write('{}\\t{}\\n'.format(data[0], data[1]))\n","          edges_old[i].append([data[0], data[1]])\n","          map_idx[i].add(data[0])\n","          map_idx[i].add(data[1])\n","        # des_f.close()\n","\n","      # des_f = open(des_filename+'_'+str(num_partition-1)+'.txt', 'w')\n","      print('Partition ', num_partition-1, '.........')\n","      for line in lines:\n","        data = line.strip('\\n').split('\\t')\n","        # des_f.write('{}\\t{}\\n'.format(data[0], data[1]))\n","        edges_old[num_partition-1].append([data[0], data[1]])\n","        map_idx[num_partition-1].add(data[0])\n","        map_idx[num_partition-1].add(data[1])\n","      # des_f.close()\n","\n","    print(\"Done!\")\n","    return map_idx, edges_old\n","\n","  def modified_vertex_idx(map_idx):\n","    map_new = {} #{node_index: {file_idx: node_index_modified},....}\n","    for key in map_idx:\n","      idx = 0\n","      for vertex in map_idx[key]:\n","        if vertex not in map_new:\n","          map_new[vertex] = {key: idx}\n","        else:\n","          map_new[vertex][key] = idx\n","        idx += 1\n","    return map_new\n","\n","  def device_vertex():\n","    with open(profiles_filename, 'r') as f:\n","      lines = f.readlines()\n","      map_vertex_labels = {}\n","      for line in lines:\n","        data = line.strip('\\n').split('\\t')\n","        map_vertex_labels[data[0]] = data[1]\n","    \n","      print('Split edge ........')\n","      map_idx, edges_old = device_edges() #{file_index: set(vertex_idxs)}\n","      print('Modify vertex index ............')\n","      new_map = modified_vertex_idx(map_idx) #{node_index_old: {file_idx: node_index_modified},....}\n","      # print(map_idx)\n","      # print(edges_old)\n","      # print(new_map)\n","\n","      # Split and update index profile\n","      print('Update index profiles:')\n","      des_filename = profiles_filename.split('.')[0]\n","      for i in range(0, num_partition):\n","        print('Partition ', i, '.........')\n","        des_f = open(des_filename+'_'+str(i)+'.txt', 'w')\n","        vertex_set = set()\n","        for vertex in map_idx[i]:\n","          vertex_set.add((new_map[vertex][i], map_vertex_labels[vertex]))\n","        vertex_set = sorted(vertex_set)\n","        for vertex in vertex_set:\n","          des_f.write('{}\\t{}\\n'.format(vertex[0], vertex[1]))\n","        des_f.close()\n","\n","      # Update index edges in relations_file_splited\n","      print('Update index relationships:')\n","      des_filename = relationships_filename.split('.')[0]\n","      for i in range(0, num_partition):\n","        print('Partition ', i, '.........')\n","        des_f = open(des_filename+'_'+str(i)+'.txt', 'w')\n","        edge_set = set()\n","        for edge in edges_old[i]:\n","          # print(edge)\n","          edge_set.add((new_map[edge[0]][i], new_map[edge[1]][i]))\n","        edge_set = sorted(edge_set)\n","        for edge in edge_set:\n","          des_f.write('{}\\t{}\\n'.format(edge[0], edge[1]))\n","        des_f.close()\n","\n","    print(\"Done!\")\n","\n","  device_vertex()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"oqTBzTL0gSn6","colab":{}},"source":["def device_k_fold(profiles_filename, relationships_filename, num_fold):\n","  def device_edges_():\n","    print('Split train data......................')\n","    map_idx = {} #{file_index: set(vertex_idxs)}\n","    edges_old = [] #edges[file_index] = [[v0,v1], ....]\n","    for i in range(0, num_fold):\n","      map_idx[i] = set()\n","      edges_old.append([])\n","\n","    # des_filename = relationships_filename.split('.')[0]\n","    with open(relationships_filename, 'r') as edges_f:\n","      print('Data reading ........')\n","      lines = edges_f.readlines()\n","      print('Cal max item_per_fold ......')\n","      max_num_items_per_partition = math.ceil(len(lines)/num_fold)\n","    \n","      lines = set(lines)\n","\n","      for i in range(0, num_fold-1):\n","        print('Partition ', i, '.........')\n","        edges = random.sample(lines, max_num_items_per_partition)\n","\n","        # des_f = open(des_filename+'_'+str(i)+'.txt', 'w')\n","        for edge in edges:\n","          lines.remove(edge)\n","          data = edge.strip('\\n').split('\\t')\n","          # des_f.write('{}\\t{}\\n'.format(data[0], data[1]))\n","          edges_old[i].append([data[0], data[1]])\n","          map_idx[i].add(data[0])\n","          map_idx[i].add(data[1])\n","        # des_f.close()\n","\n","      # des_f = open(des_filename+'_'+str(num_partition-1)+'.txt', 'w')\n","      print('Partition ', num_fold-1, '.........')\n","      for line in lines:\n","        data = line.strip('\\n').split('\\t')\n","        # des_f.write('{}\\t{}\\n'.format(data[0], data[1]))\n","        edges_old[num_fold-1].append([data[0], data[1]])\n","        map_idx[num_fold-1].add(data[0])\n","        map_idx[num_fold-1].add(data[1])\n","      # des_f.close()\n","\n","    print(\"Done!\")\n","    return map_idx, edges_old\n","\n","  def split_k_fold(map_idx, edges_old):\n","    # map_idx: {file_index: set(vertex_idxs)}\n","    # edges_old #edges[file_index] = [[v0,v1], ....]\n","\n","    fold_map = {} #{node_index: {fold_idx: node_index_modified},....}\n","    map_idx_new = {} # map_idx_new: {fold_index: set(vertex_idxs)}\n","    edges_old_new = []\n","\n","    for i in range(0, num_fold):\n","      map_idx_new[i] = set()\n","      edges_old_new.append([])\n","\n","    # map_idx_new\n","    for i in range(0, num_fold):\n","      for j in range(0, num_fold):\n","        if i != j:\n","          map_idx_new[i] = set(map_idx_new[i] | map_idx[j])\n","    # edges_old_new\n","    for i in range(0, num_fold):\n","      for j in range(0, num_fold):\n","        if i != j:\n","          edges_old_new[i] = edges_old_new[i] + edges_old[j]\n","\n","    # map_idx_new: {fold_index: set(vertex_idxs)}\n","    for fold in map_idx_new:\n","      idx = 0\n","      for vertex in map_idx_new[fold]:\n","        if vertex not in fold_map:\n","          fold_map[vertex] = {fold: idx}\n","        else:\n","          fold_map[vertex][fold] = idx\n","        idx += 1\n","\n","    # print(fold_map)\n","    # print(map_idx_new)\n","    # print(edges_old_new)\n","    return fold_map, map_idx_new, edges_old_new\n","\n","  def device_vertex_():\n","    with open(profiles_filename, 'r') as f:\n","      lines = f.readlines()\n","      map_vertex_labels = {}\n","      for line in lines:\n","        data = line.strip('\\n').split('\\t')\n","        map_vertex_labels[data[0]] = data[1]\n","\n","      print('Split edge ..........')\n","      map_idx, edges_old = device_edges_() #{file_index: set(vertex_idxs)}\n","\n","      edge = edges_old\n","      print('Modify vertex index ............')\n","      new_map, map_idx, edges_old = split_k_fold(map_idx, edges_old) #{node_index_old: {file_idx: node_index_modified},....}\n","\n","      # Split and update index profile\n","      print('Update index profiles:')\n","      des_filename = profiles_filename.split('.')[0]\n","      for i in range(0, num_fold):\n","        print('Fold ', i, '.........')\n","        des_f = open(des_filename+'_'+str(i)+'_train.txt', 'w')\n","        vertex_set = set()\n","        for vertex in map_idx[i]:\n","          vertex_set.add((new_map[vertex][i], map_vertex_labels[vertex]))\n","        vertex_set = sorted(vertex_set)\n","        for vertex in vertex_set:\n","          des_f.write('{}\\t{}\\n'.format(vertex[0], vertex[1]))\n","        des_f.close()\n","\n","      # Update index of edges in relationships_file_splited\n","      print('Update index relationships:')\n","      des_filename = relationships_filename.split('.')[0]\n","      for i in range(0, num_fold):\n","        print('Fold ', i, '.........')\n","        des_f = open(des_filename+'_'+str(i)+'_train.txt', 'w')\n","        edge_set = set()\n","        for edge in edges_old[i]:\n","          # print(edge)\n","          edge_set.add((new_map[edge[0]][i], new_map[edge[1]][i]))\n","        edge_set = sorted(edge_set)\n","        for edge in edge_set:\n","          des_f.write('{}\\t{}\\n'.format(edge[0], edge[1]))\n","        des_f.close()\n","\n","    print(\"Done!\")\n","\n","  device_vertex_()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y37YnqeTWpoy","colab_type":"code","colab":{}},"source":["# both train and test\n","def device_k_fold_v1(profiles_filename, relationships_filename, num_fold):\n","  def device_edges_():\n","    print('Split train data......................')\n","    map_idx = {} #{file_index: set(vertex_idxs)}\n","    edges_old = [] #edges[file_index] = [[v0,v1], ....]\n","    for i in range(0, num_fold):\n","      map_idx[i] = set()\n","      edges_old.append([])\n","\n","    with open(relationships_filename, 'r') as edges_f:\n","      print('Data reading ........')\n","      lines = edges_f.readlines()\n","      print('Cal max item_per_fold ......')\n","      max_num_items_per_partition = math.ceil(len(lines)/num_fold)\n","    \n","      lines = set(lines)\n","\n","      for i in range(0, num_fold-1):\n","        print('Partition ', i, '.........')\n","        edges = random.sample(lines, max_num_items_per_partition)\n","\n","        for edge in edges:\n","          lines.remove(edge)\n","          data = edge.strip('\\n').split('\\t')\n","          edges_old[i].append([data[0], data[1]])\n","          map_idx[i].add(data[0])\n","          map_idx[i].add(data[1])\n","\n","      print('Partition ', num_fold-1, '.........')\n","      for line in lines:\n","        data = line.strip('\\n').split('\\t')\n","        edges_old[num_fold-1].append([data[0], data[1]])\n","        map_idx[num_fold-1].add(data[0])\n","        map_idx[num_fold-1].add(data[1])\n","\n","    print(\"Done!\")\n","    return map_idx, edges_old\n","\n","  # Test\n","  def modified_vertex_idx(map_idx):\n","    map_new = {} #{node_index: {file_idx: node_index_modified},....}\n","    for key in map_idx:\n","      idx = 0\n","      for vertex in map_idx[key]:\n","        if vertex not in map_new:\n","          map_new[vertex] = {key: idx}\n","        else:\n","          map_new[vertex][key] = idx\n","        idx += 1\n","    return map_new\n","\n","  # Train\n","  def split_k_fold(map_idx, edges_old):\n","    # map_idx: {file_index: set(vertex_idxs)}\n","    # edges_old #edges[file_index] = [[v0,v1], ....]\n","\n","    fold_map = {} #{node_index: {fold_idx: node_index_modified},....}\n","    map_idx_new = {} # map_idx_new: {fold_index: set(vertex_idxs)}\n","    edges_old_new = []\n","\n","    for i in range(0, num_fold):\n","      map_idx_new[i] = set()\n","      edges_old_new.append([])\n","\n","    # map_idx_new\n","    for i in range(0, num_fold):\n","      for j in range(0, num_fold):\n","        if i != j:\n","          map_idx_new[i] = set(map_idx_new[i] | map_idx[j])\n","    # edges_old_new\n","    for i in range(0, num_fold):\n","      for j in range(0, num_fold):\n","        if i != j:\n","          edges_old_new[i] = edges_old_new[i] + edges_old[j]\n","\n","    # map_idx_new: {fold_index: set(vertex_idxs)}\n","    for fold in map_idx_new:\n","      idx = 0\n","      for vertex in map_idx_new[fold]:\n","        if vertex not in fold_map:\n","          fold_map[vertex] = {fold: idx}\n","        else:\n","          fold_map[vertex][fold] = idx\n","        idx += 1\n","\n","    return fold_map, map_idx_new, edges_old_new\n","\n","  def device_vertex_():\n","    with open(profiles_filename, 'r') as f:\n","      lines = f.readlines()\n","      map_vertex_labels = {}\n","      for line in lines:\n","        data = line.strip('\\n').split('\\t')\n","        map_vertex_labels[data[0]] = data[1]\n","\n","      print('Split edge ..........')\n","      map_idx_test, edges_old_test = device_edges_() #{file_index: set(vertex_idxs)}\n","      # Test\n","      print('Test - Modify vertex index ............')\n","      new_map_test = modified_vertex_idx(map_idx_test) #{node_index_old: {file_idx: node_index_modified},....}\n","      # train\n","      # edge = edges_old\n","      print('Train - Modify vertex index ............')\n","      new_map, map_idx, edges_old = split_k_fold(map_idx_test, edges_old_test) #{node_index_old: {file_idx: node_index_modified},....}\n","\n","      # Train\n","      # Split and update index profile\n","      print('Update index profiles - train:')\n","      des_filename = profiles_filename.split('.')[0]\n","      for i in range(0, num_fold):\n","        print('Fold ', i, '.........')\n","        des_f = open(des_filename+'_'+str(i)+'_train.txt', 'w')\n","        vertex_set = set()\n","        for vertex in map_idx[i]:\n","          vertex_set.add((new_map[vertex][i], map_vertex_labels[vertex]))\n","        vertex_set = sorted(vertex_set)\n","        for vertex in vertex_set:\n","          des_f.write('{}\\t{}\\n'.format(vertex[0], vertex[1]))\n","        des_f.close()\n","\n","      # Test\n","      # Split and update index profile\n","      print('Update index profiles - test:')\n","      des_filename = profiles_filename.split('.')[0]\n","      for i in range(0, num_fold):\n","        print('Partition ', i, '.........')\n","        des_f = open(des_filename+'_'+str(i)+'_test.txt', 'w')\n","        vertex_set = set()\n","        for vertex in map_idx_test[i]:\n","          vertex_set.add((new_map_test[vertex][i], map_vertex_labels[vertex]))\n","        vertex_set = sorted(vertex_set)\n","        for vertex in vertex_set:\n","          des_f.write('{}\\t{}\\n'.format(vertex[0], vertex[1]))\n","        des_f.close()\n","\n","      # Train\n","      # Update index of edges in relationships_file_splited\n","      print('Update index relationships - train:')\n","      des_filename = relationships_filename.split('.')[0]\n","      for i in range(0, num_fold):\n","        print('Fold ', i, '.........')\n","        des_f = open(des_filename+'_'+str(i)+'_train.txt', 'w')\n","        edge_set = set()\n","        for edge in edges_old[i]:\n","          # print(edge)\n","          edge_set.add((new_map[edge[0]][i], new_map[edge[1]][i]))\n","        edge_set = sorted(edge_set)\n","        for edge in edge_set:\n","          des_f.write('{}\\t{}\\n'.format(edge[0], edge[1]))\n","        des_f.close()\n","\n","\n","\n","      # Test\n","      # Update index edges in relations_file_splited\n","      print('Update index relationships - test:')\n","      des_filename = relationships_filename.split('.')[0]\n","      for i in range(0, num_fold):\n","        print('Partition ', i, '.........')\n","        des_f = open(des_filename+'_'+str(i)+'_test.txt', 'w')\n","        edge_set = set()\n","        for edge in edges_old_test[i]:\n","          # print(edge)\n","          edge_set.add((new_map_test[edge[0]][i], new_map_test[edge[1]][i]))\n","        edge_set = sorted(edge_set)\n","        for edge in edge_set:\n","          des_f.write('{}\\t{}\\n'.format(edge[0], edge[1]))\n","        des_f.close()\n","\n","    print(\"Done!\")\n","\n","  device_vertex_()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"TETYH7--pEP6","colab":{}},"source":["# convert data from gramiFormat to myDataFormat\n","def data_convert_from_Grami(source_filename, des_path): #des_profile_filename, des_relationships_filename):\n","  des_profile_filename = source_filename.split('.')[0] + '_profiles.txt' \n","  des_relationships_filename = source_filename.split('.')[0] + '_relationships.txt'\n","  with open(Grami_source_path + source_filename, 'r') as f:\n","    with open(Grami_des_path + des_profile_filename, 'w') as profiles_f:\n","      with open(Grami_des_path + des_relationships_filename, 'w') as relationships_f:\n","        vertexs_set = set()\n","        edges_set = set()\n","        vertexs_idx = set()\n","\n","        lines = f.readlines()\n","        for line in lines:\n","          data = line.strip('\\n').split(' ')\n","          if data[0] == 'v':\n","            vertexs_idx.add(data[1])\n","            vertexs_set.add((int(data[1]), int(data[2])))\n","            # profiles_f.write('{}\\t{}'.format(data[1], data[2]))\n","          if data[0] == 'e':\n","            if data[1] in vertexs_idx and data[2] in vertexs_idx:\n","              edges_set.add((int(data[1]), int(data[2])))\n","            # relationships_f.write('{}\\t{}\\n'.format(data[1], data[2]))\n","        vertexs_set = sorted(vertexs_set)\n","        edges_set = sorted(edges_set)\n","        for vertex in vertexs_set:\n","          v, l = vertex\n","          profiles_f.write('{}\\t{}\\n'.format(v, l))\n","        print('Vertex OK!')\n","        for edge in edges_set:\n","          v1, v2 = edge\n","          relationships_f.write('{}\\t{}\\n'.format(v1, v2))\n","        print('Edge OK!')\n","    print('Converted from {} to {} and {}!'.format(Grami_source_path+source_filename, Grami_des_path+des_profile_filename, Grami_des_path+des_relationships_filename))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"blbsKgk_WppN","colab_type":"code","colab":{}},"source":["# Grami_source_path = 'DATASETS/CL_10K_1d8_L5/'\n","# Grami_des_path = 'DATASETS/CL_10K_1d8_L5/'\n","# data_convert_Grami('CL_10K_1d8_L5.lg', Grami_des_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a65sJfR2WppT","colab_type":"code","colab":{}},"source":["# Convert data from mydataFormat to GramiFormat\n","def data_convert_to_Grami(profiles_filename, relationships_filename):\n","  pf_ = source_path + profiles_filename\n","  rf_ = source_path + relationships_filename\n","  des_filename = des_path + profiles_filename.split('.')[0] + '.lg'\n","  with open(pf_, 'r') as pf:\n","    with open(rf_, 'r') as rf:\n","      with open(des_filename, 'w') as f:\n","        vertexs_set = set()\n","        edges_set = set()\n","\n","        f.write('t\\t#\\t1\\n')\n","        profiles = pf.readlines()\n","        # print(profiles)\n","        for profile in profiles:\n","          data = profile.strip('\\n').split('\\t')\n","          # f.write('v {} {}\\n'.format(data[0], data[1]))\n","          vertexs_set.add((int(data[0]), int(data[1])))\n","        vertexs_set = sorted(vertexs_set)\n","        for vertex in vertexs_set:\n","          v, l = vertex\n","          f.write('v {} {}\\n'.format(v, l))\n","        print('Profiles! Done!')\n","        relationships = rf.readlines()\n","        # print(relationships)\n","        for relationship in relationships:\n","          data = relationship.strip('\\n').split('\\t')\n","          # f.write('e {} {} -1\\n'.format(data[0], data[1]))\n","          edges_set.add((int(data[0]), int(data[1])))\n","        edges_set = sorted(edges_set)\n","        for edge in edges_set:\n","          v1, v2 = edge\n","          f.write('e {} {} -1\\n'.format(v1, v2))\n","        print('Relationships! Done!')\n","  print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_dSifQO3WppZ","colab_type":"code","colab":{}},"source":["# source_path = 'DATASETS/CL_10K_1d8_L5/'\n","# des_path = 'DATASETS/CL_10K_1d8_L5/'\n","# data_convert_to_Grami('CL_10K_1d8_L5_profiles.txt', 'CL_10K_1d8_L5_relationships.txt')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2WeYYu5_gyZ2"},"source":["# Measure Acc"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"No1HGFx3gx-x","colab":{}},"source":["def get_top_pair_node(G, measure_matrix, n):\n","  set_matrix = set()\n","  for i in range(len(measure_matrix)):\n","    for j in range(len(measure_matrix)):\n","      if measure_matrix[i][j] != 0.0 and measure_matrix[i][j]  != 1.0:\n","        set_matrix.add((measure_matrix[i][j], i, j))\n","        # set_matrix.add((i, j))\n","        \n","    result = set_matrix.copy()\n","    for edge in G.edges:\n","      v1, v2, l = edge\n","      for ed in set_matrix:\n","        w_, v1_, v2_ = ed\n","        if v1==v1_ and v2==v2_:\n","          result.remove(ed)\n","  result = sorted(result, reverse=True)\n","  return set(list(result)[:n])\n","\n","def Jaccard_measure(node1, node2):\n","  if len(node1.to_nodes)==0 or len(node2.to_nodes)==0:\n","    return 0\n","  return len(set(node1.to_nodes).intersection(set(node2.to_nodes))) / len(list(set(node1.to_nodes) | set(node2.to_nodes)))\n","\n","def cal_jaccard_measure_matrix(G):\n","  result_matrix = [[0.0 for x in range(len(G.nodes))] for y in range(len(G.nodes))]\n","  for node1 in G.nodes:\n","    for node2 in G.nodes:\n","      result_matrix[node1.id][node2.id] = Jaccard_measure(node1, node2)\n","  return result_matrix\n","\n","def Jaccard_measure_v1(node1, node2):\n","  if len(node1.to_nodes)==0 or len(node2.to_nodes)==0:\n","    return 0\n","  return len(set(node1.to_nodes.union(node1.from_nodes)).intersection(set(node2.to_nodes.union(node2.from_nodes)))) / len(list(set(node1.to_nodes.union(node1.from_nodes)) | set(node2.to_nodes.union(node2.from_nodes))))\n","\n","def cal_jaccard_measure_matrix_v1(G):\n","  result_matrix = [[0.0 for x in range(len(G.nodes))] for y in range(len(G.nodes))]\n","  for node1 in G.nodes:\n","    for node2 in G.nodes:\n","      result_matrix[node1.id][node2.id] = Jaccard_measure_v1(node1, node2)\n","  return result_matrix\n","\n","def Jaccard_measure_undirected(node1, node2):\n","  if len(node1.to_nodes)==0 or len(node2.to_nodes)==0:\n","    return 0\n","  return len(set(node1.to_nodes).intersection(set(node2.to_nodes))) / len(list(set(node1.to_nodes) | set(node2.to_nodes)))\n","\n","def cal_jaccard_measure_matrix_undirected(G):\n","  result_matrix = [[0.0 for x in range(len(G.nodes))] for y in range(len(G.nodes))]\n","  for node1 in G.nodes:\n","    for node2 in G.nodes:\n","      result_matrix[node1.id][node2.id] = Jaccard_measure_undirected(node1, node2)\n","  return result_matrix\n","\n","def Simrank_measure(G, node1, node2, C):\n","  if node1.id == node2.id:\n","    return 1\n","  if len(node1.to_nodes)==0 or len(node2.to_nodes)==0:\n","    return 0\n","  sum_sim = 0\n","  for node1_ in G.nodes[node1.id].to_nodes:\n","    for node2_ in G.nodes[node2.id].to_nodes:\n","      sum_sim += Simrank_measure(G, G.nodes[node1_], G.nodes[node2_], C)\n","  return C*(sum_sim/(len(node1.to_nodes)*len(node2.to_nodes)))\n","\n","def cal_simrank_measure_matrix(G, C):\n","  result_matrix = [[0.0 for x in range(len(G.nodes))] for y in range(len(G.nodes))]\n","  for node1 in G.nodes:\n","    for node2 in G.nodes:\n","      result_matrix[node1.id][node2.id] = Simrank_measure(G, node1, node2, C)\n","  return result_matrix\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c_prEgIEWppo","colab_type":"code","colab":{}},"source":["def Simrank_measure(G, node1, node2, C, iter_, max_iter):\n","    if node1.id == node2.id:\n","        return 1\n","    if len(node1.to_nodes)==0 or len(node2.to_nodes)==0:\n","        return 0\n","    sum_sim = 0\n","    for node1_ in G.nodes[node1.id].to_nodes:\n","        for node2_ in G.nodes[node2.id].to_nodes:\n","            if iter_ <= max_iter:        \n","                sum_sim += Simrank_measure(G, G.nodes[node1_], G.nodes[node2_], C, iter_+1, max_iter)\n","    return C*(sum_sim/(len(node1.to_nodes)*len(node2.to_nodes)))\n","\n","def cal_simrank_measure_matrix(G, C, max_iter):\n","  result_matrix = [[0.0 for x in range(len(G.nodes))] for y in range(len(G.nodes))]\n","  count = 0\n","  for node1 in G.nodes:\n","    for node2 in G.nodes:\n","      count += 1\n","      if count%1000==0:\n","            print(count)\n","      result_matrix[node1.id][node2.id] = Simrank_measure(G, node1, node2, C, 0, max_iter)\n","  return result_matrix\n","\n","def Simrank_measure_v1(G, node1, node2, C, iter_, max_iter, set_edge_checked):\n","    if node1.id == node2.id:\n","        return 1\n","    if len(node1.to_nodes)==0 or len(node2.to_nodes)==0:\n","        return 0\n","    sum_sim = 0\n","    for node1_ in G.nodes[node1.id].to_nodes.union(G.nodes[node1.id].from_nodes):\n","        for node2_ in G.nodes[node2.id].to_nodes.union(G.nodes[node2.id].from_nodes):\n","            if iter_ <= max_iter:\n","                if (node1_, node2_) not in set_edge_checked:\n","                    set_edge_checked.add((node1_, node2_))\n","                    sum_sim += Simrank_measure_v1(G, G.nodes[node1_], G.nodes[node2_], C, iter_+1, max_iter, set_edge_checked)\n","    return C*(sum_sim/(len(node1.to_nodes)*len(node2.to_nodes)))\n","\n","def cal_simrank_measure_matrix_v1(G, C, max_iter):\n","  # print('Init result matrix.................')\n","  result_matrix = [[0.0 for x in range(len(G.nodes))] for y in range(len(G.nodes))]\n","  # count = 0\n","  # print('start: ')\n","  for node1 in G.nodes:\n","    # count += 1\n","    # if count%1000==0:\n","    #   print(count)\n","    for node2 in G.nodes:\n","      # print('edge: ', count, node1.id, node2.id, '.......................')\n","      result_matrix[node1.id][node2.id] = Simrank_measure_v1(G, node1, node2, C, 0, max_iter, set())\n","  return result_matrix\n","\n","# .......................\n","def simrank(G, r=0.8, max_iter=100):\n","    result_matrix = [[1.0 for x in range(len(G.nodes))] for y in range(len(G.nodes))]\n","    sim_old = [[0.0 for x in range(len(G.nodes))] for y in range(len(G.nodes))]\n","\n","    # recursively calculate simrank\n","    for iter_ctr in range(max_iter):\n","        print(' - iter: ', iter_ctr)\n","        if _is_converge(result_matrix, sim_old):\n","              break\n","        print('Copy old matrix')\n","        sim_old = copy.deepcopy(result_matrix)#result_matrix.copy()\n","        print('start cal new matrix')\n","        bar = progressbar.ProgressBar(maxval=len(G.nodes)*len(G.nodes), widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n","        bar.start()\n","        count = 0\n","        for u in range(0, len(G.nodes)):\n","            for v in range(0, len(G.nodes)):\n","                count += 1\n","                bar.update(count)\n","                if u == v:\n","                    continue\n","                s_uv = 0.0\n","                for n_u in G.nodes[u].to_nodes+G.nodes[u].from_nodes:\n","                    for n_v in G.nodes[v].to_nodes+G.nodes[v].from_nodes:\n","                        s_uv += sim_old[n_u][n_v]\n","                result_matrix[u][v] = r * s_uv / ((len(G.nodes[u].to_nodes)+len(G.nodes[u].from_nodes))*(len(G.nodes[v].to_nodes)+len(G.nodes[v].from_nodes)))\n","        bar.finish()\n","    return result_matrix\n","\n","def _is_converge(s1, s2, eps=1e-4):\n","    for i in range(0, len(s1)):\n","        for j in range(0, len(s1)):\n","            if abs(s1[i][j] - s2[i][j]) >= eps:\n","                return False\n","    return True\n","\n","def simrank_v1(G, r=0.8, max_iter=100):\n","  g = networkx.Graph()\n","  listEdges = []\n","  for edge in G.edges:\n","    v1, v2, _ = edge\n","    listEdges.append((v1, v2))\n","  g.add_edges_from(listEdges)\n","\n","  # init. vars\n","  sim_old = defaultdict(list)\n","  sim = defaultdict(list)\n","  for n in g.nodes():\n","    sim[n] = defaultdict(int)\n","    sim[n][n] = 1\n","    sim_old[n] = defaultdict(int)\n","    sim_old[n][n] = 0\n","\n","  # recursively calculate simrank\n","  for iter_ctr in range(max_iter):\n","    print('Iter ', iter_ctr)\n","    if _is_converge_v1(sim, sim_old):\n","      break\n","    sim_old = copy.deepcopy(sim)\n","    for u in g.nodes():\n","      for v in g.nodes():\n","        if u == v:\n","          continue\n","        s_uv = 0.0\n","        for n_u in g.neighbors(u):\n","          for n_v in g.neighbors(v):\n","            s_uv += sim_old[n_u][n_v]\n","        sim[u][v] = (r * s_uv / (len(list(g.neighbors(u))) * len(list(g.neighbors(v)))))\n","\n","  result = [[0.0 for x in range(len(sim))] for y in range(len(sim))]\n","  for i in sim.keys():\n","    for j in sim[i].keys():\n","      result[i][j] = sim[i][j]\n","    \n","  return result\n","\n","def _is_converge_v1(s1, s2, eps=1e-4):\n","  for i in s1.keys():\n","    for j in s1[i].keys():\n","      if abs(s1[i][j] - s2[i][j]) >= eps:\n","        return False\n","  return True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-H38sVt2Wpps","colab_type":"code","colab":{}},"source":["def countEdgeGenInPredictedEdges(edgesGen, edgesPredicted):\n","    # edgesGen: gen from rule. {(v1, v2, vlv),....}\n","    # edgesPredicted: SimRank/Jaccard top-L predicted [(similarity, v1, v2),...]\n","    set_predicted = set()\n","    for edge in edgesPredicted:\n","        _, v1, v2 = edge\n","        set_predicted.add((v1, v2))\n","        \n","    result = 0\n","    for edge in edgesGen:\n","        v1, v2, vlv = edge\n","        if (v1, v2) in set_predicted:\n","            result += 1\n","    return result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aXGER9Du2edU","colab_type":"code","colab":{}},"source":["def get_predict_all_pair_node(G, measure_matrix):\n","    print('converting measure matrix to set......')\n","    set_matrix = set()\n","    for i in range(len(measure_matrix)):\n","        for j in range(len(measure_matrix)):\n","            if measure_matrix[i][j] != 0.0 and measure_matrix[i][j]  != 1.0:\n","                set_matrix.add((measure_matrix[i][j], i, j))\n","    \n","    # Init set of Edges for graph G\n","    print('Initing set of Edges for graph G..........')\n","    edgeG_set = set()\n","    for edge in G.edges:\n","        v1, v2, _ = edge\n","        edgeG_set.add((v1, v2))\n"," \n","    # remove edge that is in G.edges\n","    print('removing edge that is in G.edges.....')\n","    result = set_matrix.copy()\n","    for edge in set_matrix:\n","        v_, v1, v2 = edge\n","        if (v1, v2) in edgeG_set:\n","            result.remove(edge)\n","    # result = sorted(result, reverse=True)\n","    return set(list(result))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x7G7NJduWppw","colab_type":"code","colab":{}},"source":["def testPipeline(dataName, supp, cnf, minTopL, maxTopL, stepTopL, KFold, NTopRules, directed_=True):\n","    import progressbar\n","    result = {'jaccard': {}, 'simrank': {}}\n","    for i in range(0, KFold):\n","        print('----------------- Fold ', i, '--------------------')\n","        if directed_:\n","          test = directed.MyGraph()\n","          train = directed.MyGraph()\n","        else:\n","            test = undirected.MyGraph()\n","            train = undirected.MyGraph()\n","        test.loadData(dataName+'_profiles_'+str(i)+'_test.txt', dataName+'_relationships_'+str(i)+'_test.txt')\n","        train.loadData(dataName+'_profiles_'+str(i)+'_train.txt', dataName+'_relationships_'+str(i)+'_train.txt')\n","        \n","        print('Minning FP.......')\n","        gc = train.FPMiner(supp)\n","        print('Gen Rules........')\n","        rules, confs = gc.ruleGen(cnf)\n","\n","        if len(rules)==0:\n","            print('Fold: ', i, ' - Not rule!')\n","    \n","\n","        except_rules = []\n","\n","        print('Gen new Edges............')\n","        bar = progressbar.ProgressBar(maxval=len(rules), widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n","        ttt = set()\n","        per = 0\n","        bar.start()\n","        for rule in rules:\n","            print(rule)\n","            if rule in except_rules:\n","              print('pass')\n","              continue\n","            ttt = ttt.union(test.genNewEdges(rule))\n","            bar.update(per+1)\n","            per += 1\n","            if per > 65:\n","              break\n","        bar.finish()\n","        \n","        print('Cal simrank_matrix........')\n","        simrank_matrix = simrank_v1(test, 0.8, 10)\n","        predict_simrank = get_predict_all_pair_node(test, simrank_matrix)\n","        predict_simrank = sorted(predict_simrank)\n","\n","        print('Cal jaccard_matrix........')\n","        jaccard_matrix = cal_jaccard_measure_matrix_undirected(test)\n","        predict_jaccard = get_predict_all_pair_node(test, jaccard_matrix)\n","        predict_jaccard = sorted(predict_jaccard)\n","        \n","        topL = minTopL\n","        while topL <= maxTopL:\n","            if topL not in result['jaccard']:\n","                result['jaccard'][topL] = {}\n","                result['simrank'][topL] = {}\n","            print('TopL = ', topL)\n","            Lrs = countEdgeGenInPredictedEdges(ttt, predict_simrank[-topL:])\n","            Lrj = countEdgeGenInPredictedEdges(ttt, predict_jaccard[-topL:])\n","            print('Jaccard: ', Lrj/topL, ' SimRank: ', Lrs/topL)\n","            print('Jaccard: ', Lrj/topL)\n","            result['jaccard'][topL][i] = Lrj/topL\n","            result['simrank'][topL][i] = Lrs/topL\n","            topL += stepTopL\n","    \n","    topL = minTopL\n","    while topL <= maxTopL:\n","        sum_sim = 0.0\n","        sum_jac = 0.0\n","        for i in range(0, KFold):\n","            sum_jac += result['jaccard'][topL][i]\n","            sum_sim += result['simrank'][topL][i]\n","        result['jaccard'][topL]['Mean'] = sum_jac/KFold\n","        result['simrank'][topL]['Mean'] = sum_sim/KFold\n","        topL += stepTopL\n","    \n","    with open(dataName+'_result_acc_rule_v5_K_'+str(KFold)+'_supp'+str(supp)+'_conf'+str(cnf)+'_directed'+str(directed_)+'.json', 'w') as f:\n","        json.dump(result, f)\n","    \n","    return result"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zAHa2de7-R6x","colab_type":"text"},"source":["# Test Pineline"]},{"cell_type":"code","metadata":{"id":"Zall07EveC3q","colab_type":"code","colab":{}},"source":["# device_k_fold_v1('DATASETS/GenTest2/genTest2_profiles.txt', 'DATASETS/GenTest2/genTest2_relationships.txt', 4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ix0NigAwK8Nb","colab_type":"code","colab":{}},"source":["# UnDirected\n","data_pool = ['DATASETS/GenTest1/genTest1','DATASETS/GenTest2/genTest2','DATASETS/CL_10K_1d8_L5/CL_10K_1d8_L5', 'DATASETS/SW_10000_6_0d3_L5/SW_10000_6_0d3_L5', 'DATASETS/cora/cora', 'DATASETS/test1/test1', 'DATASETS/test2/test2'] \n","# newTest1 -s: dir - [150, 160], undir - [150, 160]\n","# newTest2 - s: dir - [300, 320], undir - [300, 320]\n","# newTest1 -cnf: dir - [0.8, 0.9], undir - [0.8, 0.9]\n","# newTest2 - cnf: dir - [0.8, 0.9], undir - [0.8, 0.9]\n","sup_pool = [160, 300, 622, 650, 190]\n","conf_pool = [0.8, 0.8, 0.6, 0.6, 0.6]\n","minTopL = [50, 50, 50, 50, 50]\n","maxTopL = [500, 500, 500, 500, 500]\n","stepTopL = [50, 50, 50, 50, 50]\n","kFold = [4, 4, 4, 4, 4]\n","nTopRule = [5, 5, 5, 5, 5]\n","\n","for i in [1]:\n","  print('#######################', data_pool[i], '##########################')\n","  testPipeline(data_pool[i], sup_pool[i], conf_pool[i], minTopL[i], maxTopL[i], stepTopL[i], kFold[i], nTopRule[i], True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bmHg_AdWiXCg","colab_type":"text"},"source":["# Test FPMiner - Pineline"]},{"cell_type":"code","metadata":{"id":"sk-0QPxdib1p","colab_type":"code","colab":{}},"source":["def FPPineline(dataset, minsup_arr, directed_=True):\n","  if directed_:\n","    g = directed.MyGraph()\n","  else:\n","    g = undirected.MyGraph()\n","  g.loadData(dataset+'_profiles.txt', dataset+'_relationships.txt')\n","  print('numOfNodes: ', len(g.nodes), 'numOfEdges: ', len(g.edges))\n","  result = {}\n","  for minsup in minsup_arr:\n","    print('minsup: ', minsup)\n","    result[minsup] = {}\n","    print('Mining frequent patterns ...')\n","    start = time.time()\n","    fps = g.FPMiner(minsup)\n","    runTime = time.time() - start\n","    result[minsup]['runTime'] = runTime\n","    numOfFPs = fps.getNum()\n","    result[minsup]['numOfFPs'] = numOfFPs\n","    FPs = {}\n","    for fp, sup in fps.getAllData():\n","      FPs[sup] = fp\n","    result[minsup]['FPS'] = FPs\n","\n","  with open(dataset+'_FP_result.json', 'w') as f:\n","        json.dump(result, f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x0kFR4-snz_B","colab_type":"code","colab":{}},"source":["dataset_arr = ['DATASETS/cora/cora', 'DATASETS/CL_10K_1d8_L5/CL_10K_1d8_L5', 'DATASETS/SW_10000_6_0d3_L5/SW_10000_6_0d3_L5', 'DATASETS/test1/test1', 'DATASETS/test2/test2']\n","minsup_arr = [[550, 530, 466, 461], [1000, 700, 685, 680], [1450, 1400, 1050, 1000, 950, 800, 750], [315], [150, 149, 148, 147]]\n","for i in [0, 1, 2, 3, 4]:\n","  print('--------------------------', dataset_arr[i], '-------------------------')\n","  FPPineline(dataset_arr[i], minsup_arr[i], False)"],"execution_count":null,"outputs":[]}]}